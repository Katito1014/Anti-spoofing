# AASIST: Audio Anti-Spoofing Using Integrated Spectro-Temporal Graph Attention Networks



Original Paper: [AASIST: Audio Anti-Spoofing Using Integrated Spectro-Temporal Graph Attention Networks](https://arxiv.org/abs/2110.01200)



<p align="center">
	<img src="./aasist.png" alt="AASIST architecture: raw waveform â†’ temporal & spectral graphs â†’ HS-GAL blocks (heterogeneous attention + stack node) â†’ classifier" width="720" />
	<br><em>Figure 1. AASIST model architecture.</em>
</p>

## âœ¨ What's New
The work introduces the **Heterogeneous Stacking Graph Attention Layer (HS-GAL)** as an enhancement to the prior RawGAT-ST model. HS-GAL has two key components:
1. **Heterogeneous Attention** â€“ learns cross-domain (timeâ€“frequency) relationships with direction-specific projections.
2. **Stack Node** â€“ aggregates and propagates joint temporalâ€“spectral information across layers.

### ğŸ§  Heterogeneous Attention
Uses three separate projection weight sets to compute attention over a heterogeneous graph consisting of temporal and spectral nodes:
1. Time â†’ Time
2. Frequency â†’ Frequency
3. Time â†” Frequency (bidirectional, symmetric sharing)
This design allows richer cross-domain feature interaction than simple element-wise fusion.

### ğŸ§± Stack Node
The stack node acts as a global accumulator capturing mixed temporalâ€“spectral artefacts. It gathers heterogeneous messages and redistributes them, enabling deeper propagation of spoofing cues.

## ğŸ¯ Why It Matters
Integrating structured temporalâ€“spectral relations helps expose subtle artefacts indicative of spoofing systems. The proposed architecture reports up to ~20% relative improvement over the previous state-of-the-art baseline.

## ğŸ“š Literature Gap
Prior RawGAT-ST handled temporal and spectral graphs separately; fusion relied on simple element-wise combination followed by fully connected classification. This shallow fusion limited exploitation of nuanced cross-domain correlations.

## ğŸ› ï¸ Gap Closure
HS-GAL replaces naive fusion with explicit heterogeneous attention plus a stack node that repeatedly mixes and re-injects joint representations, enabling finer discrimination of spoofing artefacts across domains.

## ğŸ† Results
The model achieves state-of-the-art performance; even a published lightweight variant surpasses earlier baselines, indicating efficiency gains without excessive accuracy loss.

## ğŸ“‚ Data
Experiments use the ASVspoof 2019 Logical Access (LA) dataset. Inputs are raw 4â€‘second waveform segments (or zero-padded / clipped to duration) processed into time and frequency graphs.

## âš ï¸ Limitations
* Computational cost: Graph attention layers increase FLOPs and training time, making reproduction harder on limited GPUs.
* Hardware dependency: Original experiments used NVIDIA V100; constrained hardware may require batch size reduction or gradient accumulation.
* Potential memory overhead from maintaining heterogeneous adjacency and stack interactions.
* Paper focuses on performance; limited ablation on robustness to unseen spoofing methods or noise/reverberation.

